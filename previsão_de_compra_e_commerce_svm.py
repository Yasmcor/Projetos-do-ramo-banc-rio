# -*- coding: utf-8 -*-
"""PREVISÃO DE COMPRA E-COMMERCE_SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1P4dwRDVePvy6bLlRDgLVvK-9DjpB9QYn
"""

#Verificando a versão Python usada
from platform import python_version
print("A vesão utilizada é {}".format(python_version()))

# Dataset utilizado 
#https://archive.ics.uci.edu/ml/datasets/Online+Shoppers+Purchasing+Intention+Dataset#

# Fazer descrição do Dataset
# Fazer descrição do problema de negócio (verba de marketing para clientes que vão comprar)

# SUPORT VECTOR MACHINE SVM
# PREVER INTENÇÃO DE COMPRA DE USUÁRIOS DO E-COMMERCE

# Importando pacotes
import time
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score
from sklearn import svm
import sklearn
import matplotlib
import warnings
warnings.filterwarnings('ignore')

# Importando dataset
df = pd.read_csv('/content/online_shoppers_intention.csv')
df.head()

# Verificando tamanho do dataset
df.shape

# Verificando tipo de cada feature
df.dtypes

# Verificando valores faltantes
df.isna().sum()

# Verificando valores únicos
df.nunique().sum()

df.describe()

#separando variáveis
df_copy = df.copy()

continua = []
categorica = []

for c in df.columns[:-1]:
  if df.nunique()[c] >= 30 :
    continua.append(c)
  else:
    categorica.append(c)

df[continua] = np.log1p(1+ df[continua])

fig = plt.figure(figsize=(12,8))

for i, col in enumerate(continua):
  plt.subplot(3,3, i+1)
  df.boxplot(col)
  plt.tight_layout()

  plt.savefig("boxplot.png")

plt.subplot(1,2,2)
plt.title("Vendido ou Não")
sns.countplot(df["Revenue"])

# Plot dos visitantes do site
plt.title("Tipo de visitante")
sns.countplot(df["VisitorType"])

# Venda por tipo de visitante
pd.crosstab(df["VisitorType"], df["Revenue"]).plot(kind = "bar",
                                           figsize = (20, 5),
                                           stacked=True,
                                           color= ["orange", "blue"])

plt.pie(df['VisitorType'].value_counts(), labels=["Visitante retornando", "Novo visitante", "Outro"],
        autopct="%2.f%%")
plt.title("Tipos de visitantes")
plt.legend()

# Venda por tipo de visitante
pd.crosstab(df["Weekend"], df["Revenue"]).plot(kind = "bar",
                                           figsize = (20, 5),
                                           stacked=True,
                                           color= ["orange", "blue"])

plt.title("Tipo de tráfego")
plt.xlabel("Tipo de tráfego")
sns.countplot(df["TrafficType"])

# Venda por tipo de visitante
pd.crosstab(df["TrafficType"], df["Revenue"]).plot(kind = "bar",
                                           figsize = (20, 5),
                                           stacked=True,
                                           color= ["orange", "blue"])

"""###PRÉ PROCESSAMENTO DE DADOS"""

# Transformando váriáveis que são strings
lb = LabelEncoder()

df["Month"] = lb.fit_transform(df["Month"])
df["VisitorType"] = lb.fit_transform(df["Month"])

# Removendo Valores missing eventualmente criados
df.dropna(inplace=True)

df.head()

sns.countplot(df.Revenue, palette="OrRd")
plt.box(False)
plt.xlabel("Receita (Revenue) Por Sessão Não(0)/ Sim(1)", fontsize= 11)
plt.ylabel("Total de sessões", fontsize= 11)
plt.title("Contagem de classes\n")

import imblearn

"""###BALANCEAMENTO DE CLASSES - OVERSAMPILIG"""

from imblearn.over_sampling import SMOTE

seed = 100

# Separando variáveis explicativas e target
x = df.iloc[:,0:17]
y = df.iloc[:, 17]

# Criando Balanceador SMOTE
balanceador = SMOTE(random_state=seed)

# Aplicando o Balanceador
x_balanc, y_balanc = balanceador.fit_resample(x, y)

# Vizualização do novo conjunto de dados

sns.countplot(y_balanc, palette= "OrRd")
plt.box(False)
plt.xlabel("Receita (Revenue) Por Sessão Não(0)/ Sim(1)", fontsize= 11)
plt.ylabel("Total de sessões", fontsize= 11)
plt.title("Contagem de classes\n")

x = x_balanc
y = y_balanc

# Divisão dos dados em treino e teste

x_treino,  x_test, y_treino, y_test = train_test_split(x, y, test_size = 0.3, random_state=42)

"""MODELO BASELINE"""

# Criando modelo 
modelo_v1 = svm.SVC(kernel= "linear")


# Treinando o modelo
start = time.time()
modelo_v1.fit(x_treino, y_treino)
end = time.time()
print("Tempo de treinamento do modelo: {:0.2f} s".format(end - start))

# Fazendo novas previsões com dados de teste

modelo_v1_predicoes = modelo_v1.predict(x_test)

Predições_v1 = {"Modelo": "SVM", "Versão": "1",
                "Kernel": "Linear",
                "Precisão": precision_score(modelo_v1_predicoes, y_test),
                "Recall": recall_score(modelo_v1_predicoes, y_test),
                "F1 Score": f1_score(modelo_v1_predicoes, y_test),
                "Acurácia": accuracy_score(modelo_v1_predicoes, y_test),
                "AUX": roc_auc_score(y_test, modelo_v1_predicoes)}

print('Métricas do modelo\n')
Predições_v1

"""###MODELO COM KERNEL LINEAR COM DADOS PADRONIZADOS"""

sc = StandardScaler()
x_treino_scaled = sc.fit_transform(x_treino)
x_teste_scaled = sc.fit_transform(x_test)

modelo_v2 = svm.SVC(kernel="linear")

# Criando modelo 
modelo_v2 = svm.SVC(kernel= "linear")


# Treinando o modelo
start = time.time()
modelo_v2.fit(x_treino, y_treino)
end = time.time()
print("Tempo de treinamento do modelo: {:0.2f} s".format(end - start))

modelo_v2_predicoes = modelo_v2.predict(x_test)

Predições_v2 = {"Modelo": "SVM", "Versão": "2",
                "Kernel": "Linear",
                "Precisão": precision_score(modelo_v2_predicoes, y_test),
                "Recall": recall_score(modelo_v2_predicoes, y_test),
                "F1 Score": f1_score(modelo_v2_predicoes, y_test),
                "Acurácia": accuracy_score(modelo_v2_predicoes, y_test),
                "AUX": roc_auc_score(y_test, modelo_v2_predicoes)}
Predições_v2

"""otimização de hiperparametros e grid search kernel RBF"""

# Criando modelo 
modelo_v3 = svm.SVC(kernel= "rbf")

# Valores para o grid
c_range = np.array([50, 100, 200])
gamma_range = np.array([0.3*0.001, 0.001,3*0.001])

#Grid de hiperparametros
svm_param_grid = dict(gamma = gamma_range, C= c_range)

# Grid Seach
start = time.time()
modelo_v3_grid_search_rbf = GridSearchCV(modelo_v3,svm_param_grid, cv= 3)

# Treinando o modelo

modelo_v3_grid_search_rbf.fit(x_treino_scaled, y_treino)
end = time.time()
print("Tempo de treinamento do modelo: {:0.2f} s".format(end - start))

# Acurácia do treinamento 
print(f"acurácia:{modelo_v3_grid_search_rbf.best_score_ :.2%}")
print(f"Hiperparametros ideias:{modelo_v3_grid_search_rbf.best_params_}")

modelo_v3_predicoes = modelo_v3_grid_search_rbf.predict(x_teste_scaled)

Predições_v3 = {"Modelo": "SVM", "Versão": "3",
                "Kernel": "rbf com dados padronizados",
                "Precisão": precision_score(modelo_v3_predicoes, y_test),
                "Recall": recall_score(modelo_v3_predicoes, y_test),
                "F1 Score": f1_score(modelo_v3_predicoes, y_test),
                "Acurácia": accuracy_score(modelo_v3_predicoes, y_test),
                "AUX": roc_auc_score(y_test, modelo_v3_predicoes)}

Predições_v3

"""###OTIMIZAÇÃO DE HIPERPARAMETROS COM GRID SEACH E KERNEL POLINOMINAL"""

# Criando modelo 
modelo_v4 = svm.SVC(kernel= "poly")

# Valores para o grid
r_range = np.array([0.5, 1])
gamma_range = np.array([0.001, 0.01])
d_range = np.array([2,3,4])

#Grid de hiperparametros
param_grid_poly = dict(gamma = gamma_range,degree =d_range, coef0= r_range)

# Grid Seach
start = time.time()
modelo_v4_grid_search_poly = GridSearchCV(modelo_v4, param_grid_poly, cv= 3)

# Treinando o modelo

modelo_v4_grid_search_poly.fit(x_treino_scaled, y_treino)
end = time.time()
print("Tempo de treinamento do modelo: {:0.2f} s".format(end - start))

# Acurácia do treinamento 
print(f"acurácia:{modelo_v4_grid_search_poly.best_score_ :.2%}")
print(f"Hiperparametros ideias:{modelo_v4_grid_search_poly.best_params_}")

modelo_v4_predicoes = modelo_v4_grid_search_poly.predict(x_teste_scaled)

Predições_v4 = {"Modelo": "SVM", "Versão": "4",
                "Kernel": "polinominal com dados padronizados",
                "Precisão": precision_score(modelo_v4_predicoes, y_test),
                "Recall": recall_score(modelo_v4_predicoes, y_test),
                "F1 Score": f1_score(modelo_v4_predicoes, y_test),
                "Acurácia": accuracy_score(modelo_v4_predicoes, y_test),
                "AUX": roc_auc_score(y_test, modelo_v4_predicoes)}

Predições_v4

resultado_modelos = pd.DataFrame({"Versão1":pd.Series(Predições_v1),
                                 "Versão2": pd.Series(Predições_v2),
                                 "Versão3": pd.Series(Predições_v3),
                                 "Versão4": pd.Series(Predições_v4)})
resultado_modelos

